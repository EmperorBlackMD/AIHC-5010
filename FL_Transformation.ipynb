{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqPPAu425TumppdKmJ+gHm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmperorBlackMD/AIHC-5010/blob/main/FL_Transformation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2WBKOzEbJgrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "450a6588-ea46-46eb-b5f1-6801f36a7e5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading my file\n",
        "import pandas as pd\n",
        "\n",
        "path = '/content/drive/MyDrive/FL_project/FL_data.xlsx'\n",
        "df = pd.read_excel(path)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "f9xrAGoENBDv",
        "outputId": "c04ffba6-e754-41c0-b180-ab061cb639db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             MER ERA  Mayo Clinic Number Clinic ID  MER ID  \\\n",
              "0  MER 2.0 (07/01/2015 - 07/31/2021)           4853674.0   4853674     NaN   \n",
              "1  MER 2.0 (07/01/2015 - 07/31/2021)           7551765.0   7551765     NaN   \n",
              "2  MER 2.0 (07/01/2015 - 07/31/2021)           7711429.0   7711429     NaN   \n",
              "3         MER 1.0 (2002- 06/30/2015)           1018649.0   1018649  MC1689   \n",
              "4  MER 2.0 (07/01/2015 - 07/31/2021)          10258704.0  10258704     NaN   \n",
              "\n",
              "     LEO ID  Age @ Diagnosis  Gender   Race               Ethnicity  \\\n",
              "0  MA117104               78    Male  White  Not Hispanic or Latino   \n",
              "1  MA116538               77    Male  White  Not Hispanic or Latino   \n",
              "2  MA117068               77    Male  White  Not Hispanic or Latino   \n",
              "3       NaN               67  Female  White  Not Hispanic or Latino   \n",
              "4  MC119987               65    Male  White  Not Hispanic or Latino   \n",
              "\n",
              "  Diagnosis\\nBiopsy Date  ... Tumor Size 1 Funky Dx    Tissue Status  \\\n",
              "0             2018-06-18  ...          NaN      NaN              NaN   \n",
              "1             2018-03-27  ...          NaN      NaN              NaN   \n",
              "2             2018-02-22  ...          NaN      NaN              NaN   \n",
              "3             2005-08-22  ...          2.0      NaN  Tissue exhaused   \n",
              "4             2019-09-30  ...          NaN      NaN              NaN   \n",
              "\n",
              "  Tumor % 2  Tumor Size 2 Tumor % 3 Tumor Size 3 Tumor % 4 Tumor Size 4  \\\n",
              "0       NaN           NaN       NaN          NaN       NaN          NaN   \n",
              "1       NaN           NaN       NaN          NaN       NaN          NaN   \n",
              "2       NaN           NaN       NaN          NaN       NaN          NaN   \n",
              "3       NaN           NaN       NaN          NaN       NaN          NaN   \n",
              "4       NaN           NaN       NaN          NaN       NaN          NaN   \n",
              "\n",
              "     Accession Available  \n",
              "0  Accession # Available  \n",
              "1  Accession # Available  \n",
              "2  Accession # Available  \n",
              "3  Accession # Available  \n",
              "4  Accession # Available  \n",
              "\n",
              "[5 rows x 83 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c78c392f-0d3a-4c63-9cd5-81f3af16c9bd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MER ERA</th>\n",
              "      <th>Mayo Clinic Number</th>\n",
              "      <th>Clinic ID</th>\n",
              "      <th>MER ID</th>\n",
              "      <th>LEO ID</th>\n",
              "      <th>Age @ Diagnosis</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Race</th>\n",
              "      <th>Ethnicity</th>\n",
              "      <th>Diagnosis\\nBiopsy Date</th>\n",
              "      <th>...</th>\n",
              "      <th>Tumor Size 1</th>\n",
              "      <th>Funky Dx</th>\n",
              "      <th>Tissue Status</th>\n",
              "      <th>Tumor % 2</th>\n",
              "      <th>Tumor Size 2</th>\n",
              "      <th>Tumor % 3</th>\n",
              "      <th>Tumor Size 3</th>\n",
              "      <th>Tumor % 4</th>\n",
              "      <th>Tumor Size 4</th>\n",
              "      <th>Accession Available</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MER 2.0 (07/01/2015 - 07/31/2021)</td>\n",
              "      <td>4853674.0</td>\n",
              "      <td>4853674</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MA117104</td>\n",
              "      <td>78</td>\n",
              "      <td>Male</td>\n",
              "      <td>White</td>\n",
              "      <td>Not Hispanic or Latino</td>\n",
              "      <td>2018-06-18</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Accession # Available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MER 2.0 (07/01/2015 - 07/31/2021)</td>\n",
              "      <td>7551765.0</td>\n",
              "      <td>7551765</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MA116538</td>\n",
              "      <td>77</td>\n",
              "      <td>Male</td>\n",
              "      <td>White</td>\n",
              "      <td>Not Hispanic or Latino</td>\n",
              "      <td>2018-03-27</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Accession # Available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MER 2.0 (07/01/2015 - 07/31/2021)</td>\n",
              "      <td>7711429.0</td>\n",
              "      <td>7711429</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MA117068</td>\n",
              "      <td>77</td>\n",
              "      <td>Male</td>\n",
              "      <td>White</td>\n",
              "      <td>Not Hispanic or Latino</td>\n",
              "      <td>2018-02-22</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Accession # Available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MER 1.0 (2002- 06/30/2015)</td>\n",
              "      <td>1018649.0</td>\n",
              "      <td>1018649</td>\n",
              "      <td>MC1689</td>\n",
              "      <td>NaN</td>\n",
              "      <td>67</td>\n",
              "      <td>Female</td>\n",
              "      <td>White</td>\n",
              "      <td>Not Hispanic or Latino</td>\n",
              "      <td>2005-08-22</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tissue exhaused</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Accession # Available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MER 2.0 (07/01/2015 - 07/31/2021)</td>\n",
              "      <td>10258704.0</td>\n",
              "      <td>10258704</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MC119987</td>\n",
              "      <td>65</td>\n",
              "      <td>Male</td>\n",
              "      <td>White</td>\n",
              "      <td>Not Hispanic or Latino</td>\n",
              "      <td>2019-09-30</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Accession # Available</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 83 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c78c392f-0d3a-4c63-9cd5-81f3af16c9bd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c78c392f-0d3a-4c63-9cd5-81f3af16c9bd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c78c392f-0d3a-4c63-9cd5-81f3af16c9bd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Column mapping\n",
        "COLS = {\n",
        "    \"id\": \"Clinic ID\",\n",
        "    \"age\": \"Age @ Diagnosis\",\n",
        "    \"sex\": \"Gender\",\n",
        "    \"race\": \"Race\",\n",
        "    \"dx_date\": \"Diagnosis Biopsy Date\",\n",
        "    \"histology\": \"Biopsy Histology\",\n",
        "    \"ht\": \"Transformation\",\n",
        "    \"ht_date\": \"Date of transformation\",\n",
        "    \"pod24\": \"EFS24\",\n",
        "    \"vital\": \"Vital Status\",\n",
        "    \"fu_months\": \"FU Months\",\n",
        "    \"efs_status\": \"EFS Status\",\n",
        "    \"efs_months\": \"EFS months\",\n",
        "    \"cod\": \"Primary COD\",\n",
        "    \"bulky\": \"Bulky Disease\",\n",
        "    \"b_symptoms\": \"B Symptoms\",\n",
        "    \"stage\": \"Ann Arbor Stage\",\n",
        "    \"amc\": \"AMC\",\n",
        "    \"alc\": \"ALC\",\n",
        "    \"anc\": \"ANC\",\n",
        "    \"bili\": \"Bilirubin (mg dL)\",\n",
        "    \"wbc\": \"WBC (x109 L o K mm3)\",\n",
        "    \"plt\": \"PLT (x109 L)\",\n",
        "    \"hgb\": \"HGB (g dL)\",\n",
        "    \"alb\": \"Serum Albumin (g dL)\",\n",
        "    \"cr\": \"Creatinine (mg dL)\",\n",
        "    \"age_group\": \"Age Group\",\n",
        "    \"stage_group\": \"Ann Arbor Stage Group\",\n",
        "    \"ps_group\": \"PS Group\",\n",
        "    \"ldh_group\": \"LDH Group\",\n",
        "    \"ex_sites\": \"Num of Ex. Sites\",\n",
        "    \"flipi\": \"FLIPI\",\n",
        "    \"flipi_group\": \"FLIPI Group\",\n",
        "    \"immunochemo\": \"FL Immuno-chemo\",\n",
        "    \"bm_group\": \"BM Involvement Group\",\n",
        "    \"multi_hist\": \"Multiple FL Histologies\",\n",
        "    \"fl_grade\": \"FL Grade\",\n",
        "}"
      ],
      "metadata": {
        "id": "q2vqh_sWVPMs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure ID uniqueness\n",
        "n = len(df)\n",
        "n_unique = df[COLS['id']].nunique(dropna=False)\n",
        "print('Rows:', n, '| Unique IDs:', n_unique)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqnPC9QmW8Jm",
        "outputId": "ddb5514d-44f0-435a-83ea-f973402b6672"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 1987 | Unique IDs: 1987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse dates\n",
        "for dcol in [COLS['dx_date'], COLS['ht_date']]:\n",
        "    if dcol in df.columns:\n",
        "        df[dcol] = pd.to_datetime(df[dcol], errors='coerce')\n",
        "\n",
        "# Normalize common binary/categorical encodings\n",
        "def map_yes_no(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    s = str(x).strip().lower()\n",
        "    if s in [\"yes\", \"y\", \"1\", \"true\", \"t\"]: return 1\n",
        "    if s in [\"no\", \"n\", \"0\", \"false\", \"f\"]: return 0\n",
        "    return np.nan\n",
        "\n",
        "# Histologic transformation\n",
        "if COLS[\"ht\"] in df.columns:\n",
        "    df[\"_ht01\"] = df[COLS[\"ht\"]].map(map_yes_no)\n",
        "\n",
        "# Bulky, B symptoms, immunochemo if yes/no\n",
        "for c in [\"bulky\", \"b_symptoms\", \"immunochemo\"]:\n",
        "    col = COLS.get(c)\n",
        "    if col in df.columns:\n",
        "        df[f\"_{c}01\"] = df[col].map(map_yes_no)\n",
        "\n",
        "# Vital status\n",
        "if COLS[\"vital\"] in df.columns:\n",
        "    def map_vital(x):\n",
        "        if pd.isna(x): return np.nan\n",
        "        s = str(x).strip().lower()\n",
        "        if \"Deceased\" in s or \"dead\" in s: return 1\n",
        "        if \"Alive\" in s: return 0\n",
        "        return np.nan\n",
        "    df[\"_dead01\"] = df[COLS[\"vital\"]].map(map_vital)\n",
        "\n",
        "# EFS status\n",
        "if COLS[\"efs_status\"] in df.columns:\n",
        "    def map_event(x):\n",
        "        if pd.isna(x): return np.nan\n",
        "        s = str(x).strip().lower()\n",
        "        if \"event\" in s: return 1\n",
        "        if \"no event\" in s or \"No event\" in s: return 0\n",
        "        return np.nan\n",
        "    df[\"_efs_event01\"] = df[COLS[\"efs_status\"]].map(map_event)\n",
        "\n",
        "# EFS24 (<24m are blank) into a numeric binary\n",
        "def parse_efs24_to_bin(x):\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "    s = str(x).strip().lower()\n",
        "    if s == \"\":\n",
        "        return np.nan\n",
        "    if \"fail\" in s:\n",
        "        return 1\n",
        "    if \"achiev\" in s:\n",
        "        return 0\n",
        "    return np.nan  # unexpected category\n",
        "\n",
        "df[\"EFS24_bin\"] = df[\"EFS24\"].apply(parse_efs24_to_bin)\n",
        "\n",
        "# -- Numeric coercion for labs and key numeric fields ----------\n",
        "numeric_cols = [\n",
        "    COLS[\"age\"], COLS[\"amc\"], COLS[\"alc\"], COLS[\"anc\"], COLS[\"bili\"],\n",
        "    COLS[\"wbc\"], COLS[\"plt\"], COLS[\"hgb\"], COLS[\"alb\"], COLS[\"cr\"],\n",
        "    COLS[\"fu_months\"], COLS[\"efs_months\"], COLS[\"ex_sites\"], COLS[\"flipi\"]\n",
        "]\n",
        "for c in numeric_cols:\n",
        "    if c in df.columns:\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")"
      ],
      "metadata": {
        "id": "1jyVAUKzXuZk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missingness summary (focused columns) ----------\n",
        "focus_cols = list(COLS.values())\n",
        "focus_cols = [c for c in focus_cols if c in df.columns]\n",
        "miss = df[focus_cols].isna().mean().sort_values(ascending=False)\n",
        "print(\"\\nMissingness (fraction):\\n\", miss.head(25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Prdjltw8a9O4",
        "outputId": "be37310f-8905-4bf2-9a4f-e7b1b978c659"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missingness (fraction):\n",
            " Date of transformation    0.910418\n",
            "ANC                       0.411173\n",
            "AMC                       0.315048\n",
            "ALC                       0.191746\n",
            "LDH Group                 0.173125\n",
            "EFS24                     0.122798\n",
            "BM Involvement Group      0.085556\n",
            "Bulky Disease             0.075994\n",
            "Ann Arbor Stage           0.051334\n",
            "Ann Arbor Stage Group     0.051334\n",
            "Num of Ex. Sites          0.045798\n",
            "PS Group                  0.036236\n",
            "FL Immuno-chemo           0.017111\n",
            "B Symptoms                0.004529\n",
            "Primary COD               0.003523\n",
            "FL Grade                  0.001510\n",
            "Clinic ID                 0.000000\n",
            "Age @ Diagnosis           0.000000\n",
            "Gender                    0.000000\n",
            "Race                      0.000000\n",
            "FU Months                 0.000000\n",
            "EFS Status                0.000000\n",
            "Transformation            0.000000\n",
            "Vital Status              0.000000\n",
            "Age Group                 0.000000\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing_vars = {\n",
        "    \"ANC\": \"ANC\",\n",
        "    \"AMC\": \"AMC\",\n",
        "    \"ALC\": \"ALC\",\n",
        "    \"LDH_group\": \"LDH Group\"\n",
        "}\n",
        "\n",
        "for k, col in missing_vars.items():\n",
        "    if col in df.columns:\n",
        "     df[f\"miss_{k}\"] = df[col].isna().astype(int)\n",
        "\n",
        "# Quick prevalence check\n",
        "for k in missing_vars:\n",
        "    print(k, df[f\"miss_{k}\"].mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkvH1a8ve4KQ",
        "outputId": "0140dcbf-cb9a-4104-f4bf-2705fbcf2755"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANC 0.4111726220432813\n",
            "AMC 0.31504781077000504\n",
            "ALC 0.19174635128334172\n",
            "LDH_group 0.1731253145445395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Little's test to check MCAR\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "\n",
        "def little_mcar_test(data):\n",
        "    \"\"\"\n",
        "    Little's MCAR test.\n",
        "    data: pandas DataFrame with only variables to test (numeric preferred).\n",
        "    \"\"\"\n",
        "    X = data.copy()\n",
        "\n",
        "    # Drop rows with all missing\n",
        "    X = X.dropna(how=\"all\")\n",
        "\n",
        "    # Mean vector\n",
        "    mean_vec = X.mean(skipna=True).values\n",
        "\n",
        "    # Covariance matrix\n",
        "    cov = X.cov()\n",
        "\n",
        "    test_stat = 0\n",
        "    df_total = 0\n",
        "\n",
        "    for pattern, group in X.groupby(X.isna().apply(tuple, axis=1)):\n",
        "        observed = ~np.array(pattern)\n",
        "        group_obs = group.loc[:, observed]\n",
        "\n",
        "        if group_obs.shape[0] <= 1:\n",
        "            continue\n",
        "\n",
        "        mean_diff = group_obs.mean().values - mean_vec[observed]\n",
        "        cov_obs = cov.loc[group_obs.columns, group_obs.columns].values\n",
        "\n",
        "        try:\n",
        "            inv_cov = np.linalg.inv(cov_obs)\n",
        "        except np.linalg.LinAlgError:\n",
        "            continue\n",
        "\n",
        "        test_stat += group_obs.shape[0] * mean_diff.T @ inv_cov @ mean_diff\n",
        "        df_total += observed.sum()\n",
        "\n",
        "    p_value = 1 - stats.chi2.cdf(test_stat, df_total)\n",
        "    return test_stat, df_total, p_value\n",
        "\n",
        "labs_for_mcar = df[\n",
        "    [\"ANC\", \"AMC\", \"ALC\"]\n",
        "].copy()\n",
        "\n",
        "stat, dof, p = little_mcar_test(labs_for_mcar)\n",
        "\n",
        "print(f\"Little's MCAR test: χ²={stat:.2f}, df={dof}, p={p:.4g}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnhfnw1sfFyO",
        "outputId": "661bcd84-a190-4cf2-cc98-70da4e6ce553"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Little's MCAR test: χ²=7.92, df=7, p=0.3399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cHECK IF MISSINGNESS IS ASSOCIATEED WITH BASELINE CLINICAL VARIABLES\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import numpy as np\n",
        "\n",
        "predictors = [\n",
        "    \"Age @ Diagnosis\",\n",
        "    \"Ann Arbor Stage Group\",\n",
        "    \"FLIPI Group\",\n",
        "    \"Bulky Disease\",\n",
        "    \"B Symptoms\",\n",
        "    \"EFS24_bin\"\n",
        "]\n",
        "\n",
        "if 'EFS24_bin' in df.columns:\n",
        "    df['EFS24_bin'] = pd.to_numeric(df['EFS24_bin'], errors='coerce')\n",
        "# Prepare X with dummies and force all columns to numeric\n",
        "Xraw = df[predictors].copy()\n",
        "\n",
        "# Convert obvious numeric columns\n",
        "if \"Age @ Diagnosis\" in Xraw.columns:\n",
        "    Xraw[\"Age @ Diagnosis\"] = pd.to_numeric(Xraw[\"Age @ Diagnosis\"], errors=\"coerce\")\n",
        "\n",
        "# Convert all categorical to string consistently (prevents mixed-type dummies)\n",
        "cat_cols = [c for c in Xraw.columns if c != \"Age @ Diagnosis\"]\n",
        "for c in cat_cols:\n",
        "    Xraw[c] = Xraw[c].astype(\"string\")\n",
        "\n",
        "Xdum = pd.get_dummies(Xraw, drop_first=True)\n",
        "\n",
        "# Force everything to numeric (key fix)\n",
        "Xdum = Xdum.apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "# Add constant AFTER numeric conversion\n",
        "Xdum = sm.add_constant(Xdum, has_constant=\"add\")\n",
        "\n",
        "# Fit a missingness model for each variable\n",
        "for k in missing_vars.keys():\n",
        "    miss_col = f\"miss_{k}\"\n",
        "    if miss_col not in df.columns:\n",
        "        continue\n",
        "\n",
        "    y = df[miss_col]\n",
        "    y = pd.to_numeric(y, errors=\"coerce\")\n",
        "\n",
        "    # Combine and drop rows with any NA in X or y\n",
        "    tmp = pd.concat([y.rename(\"y\"), Xdum], axis=1).dropna()\n",
        "    y_clean = tmp[\"y\"].astype(int)\n",
        "    X_clean = tmp.drop(columns=[\"y\"]).astype(float)\n",
        "\n",
        "    # Skip degenerate cases\n",
        "    if y_clean.nunique() < 2:\n",
        "        print(f\"\\nMissingness model for {k}: skipped (outcome has <2 classes after dropping NAs)\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        model = sm.Logit(y_clean, X_clean).fit(disp=False)\n",
        "        print(f\"\\nMissingness model for {k} (miss_{k}=1 means {k} is missing)\")\n",
        "        out = model.summary2().tables[1][[\"Coef.\", \"Std.Err.\", \"P>|z|\"]].sort_values(\"P>|z|\")\n",
        "        print(out.head(15))\n",
        "    except Exception as e:\n",
        "        print(f\"\\nMissingness model for {k}: FAILED with error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtBVe3fDfmZq",
        "outputId": "4249a27f-73f0-4fe5-a716-bacbe7606fa4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missingness model for ANC (miss_ANC=1 means ANC is missing)\n",
            "                                 Coef.  Std.Err.     P>|z|\n",
            "Age @ Diagnosis              -0.017925  0.003856  0.000003\n",
            "B Symptoms_Unconfirmed        1.445231  0.332891  0.000014\n",
            "EFS24_bin_1.0                 0.296445  0.109527  0.006798\n",
            "const                         0.653889  0.245315  0.007687\n",
            "Bulky Disease_Yes            -0.339462  0.166528  0.041503\n",
            "B Symptoms_Yes               -0.180683  0.145146  0.213194\n",
            "FLIPI Group_2 Intermediate    0.024073  0.131080  0.854287\n",
            "Ann Arbor Stage Group_III-IV  0.009808  0.127465  0.938664\n",
            "FLIPI Group_3 High            0.000150  0.159972  0.999252\n",
            "\n",
            "Missingness model for AMC (miss_AMC=1 means AMC is missing)\n",
            "                                 Coef.  Std.Err.         P>|z|\n",
            "B Symptoms_Unconfirmed        1.775673  0.333367  1.001362e-07\n",
            "Age @ Diagnosis              -0.016779  0.004062  3.614323e-05\n",
            "B Symptoms_Yes               -0.408556  0.163283  1.234490e-02\n",
            "Bulky Disease_Yes            -0.299705  0.182529  1.005998e-01\n",
            "const                         0.278755  0.257206  2.784613e-01\n",
            "EFS24_bin_1.0                 0.123557  0.116973  2.908376e-01\n",
            "FLIPI Group_3 High           -0.101826  0.171146  5.518640e-01\n",
            "Ann Arbor Stage Group_III-IV -0.059943  0.134209  6.551357e-01\n",
            "FLIPI Group_2 Intermediate    0.016871  0.137946  9.026580e-01\n",
            "\n",
            "Missingness model for ALC (miss_ALC=1 means ALC is missing)\n",
            "                                 Coef.  Std.Err.         P>|z|\n",
            "B Symptoms_Unconfirmed        2.469816  0.343530  6.501999e-13\n",
            "const                        -1.153766  0.310059  1.983406e-04\n",
            "FLIPI Group_3 High           -0.684692  0.212899  1.299694e-03\n",
            "FLIPI Group_2 Intermediate   -0.327963  0.164503  4.618991e-02\n",
            "EFS24_bin_1.0                -0.211738  0.148193  1.530613e-01\n",
            "Bulky Disease_Yes             0.132802  0.204731  5.165521e-01\n",
            "Age @ Diagnosis              -0.002289  0.004874  6.385983e-01\n",
            "Ann Arbor Stage Group_III-IV  0.066076  0.158113  6.760179e-01\n",
            "B Symptoms_Yes               -0.057360  0.190418  7.632363e-01\n",
            "\n",
            "Missingness model for LDH_group (miss_LDH_group=1 means LDH_group is missing)\n",
            "                                 Coef.  Std.Err.         P>|z|\n",
            "B Symptoms_Unconfirmed        2.505264  0.338486  1.347741e-13\n",
            "FLIPI Group_3 High           -1.538593  0.244995  3.383734e-10\n",
            "const                        -1.783660  0.333983  9.265459e-08\n",
            "FLIPI Group_2 Intermediate   -0.673666  0.172298  9.233851e-05\n",
            "B Symptoms_Yes                0.358365  0.188434  5.719629e-02\n",
            "Ann Arbor Stage Group_III-IV  0.244432  0.163428  1.347442e-01\n",
            "Age @ Diagnosis               0.006647  0.005203  2.014505e-01\n",
            "Bulky Disease_Yes            -0.130429  0.234424  5.779497e-01\n",
            "EFS24_bin_1.0                 0.045396  0.150990  7.636755e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ANC missingness (41% missing) — clearly NOT MCAR\n",
        "\n",
        "Key predictors:\n",
        "\n",
        "Age @ Diagnosis (p = 3e-6):\n",
        "Older patients are less likely to have ANC missing (negative coefficient).\n",
        "\n",
        "B Symptoms = Unconfirmed (p = 1e-5):\n",
        "Strong association → documentation/workup intensity effect.\n",
        "\n",
        "EFS24 failure (p = 0.007):\n",
        "Missingness differs by outcome → very strong evidence against MCAR.\n",
        "\n",
        "Bulky Disease (p = 0.04):\n",
        "Suggests disease burden/workup differences.\n",
        "\n",
        "Conclusion: ANC missingness is MAR, possibly outcome-informative.\n",
        "\n",
        "#AMC missingness (32% missing) — NOT MCAR\n",
        "\n",
        "Key predictors:\n",
        "\n",
        "B Symptoms = Unconfirmed (p ≈ 1e-7)\n",
        "\n",
        "Age @ Diagnosis (p ≈ 4e-5)\n",
        "\n",
        "B Symptoms = Yes (p = 0.012)\n",
        "\n",
        "Outcome (EFS24) is not significant here, but baseline predictors are.\n",
        "\n",
        "Conclusion: AMC missingness is MAR, driven by clinical documentation/workup patterns.\n",
        "\n",
        "#ALC missingness (19% missing) — NOT MCAR\n",
        "\n",
        "Key predictors:\n",
        "\n",
        "B Symptoms = Unconfirmed (p ≈ 6e-13)\n",
        "\n",
        "FLIPI Group (Intermediate/High) (p = 0.046 / 0.001)\n",
        "\n",
        "This is important: prognostic risk itself predicts missingness, which is classic MAR.\n",
        "\n",
        "Conclusion: ALC missingness is MAR, tied to disease risk.\n",
        "\n",
        "# LDH group missingness (17% missing) — strongly NOT MCAR\n",
        "\n",
        "Key predictors:\n",
        "\n",
        "B Symptoms = Unconfirmed (p ≈ 1e-13)\n",
        "\n",
        "FLIPI Group (Intermediate/High) (p ≈ 1e-4 / 3e-10)\n",
        "\n",
        "This is textbook:\n",
        "\n",
        "Low-risk patients often lack LDH documentation\n",
        "\n",
        "High-risk patients almost always have LDH measured\n",
        "\n",
        "Conclusion: LDH missingness is MAR, and this is extremely common in lymphoma datasets.\n",
        "\n",
        "\n",
        "##Missingness was assessed using logistic regression models predicting missingness from baseline clinical variables. Missingness for ANC, AMC, ALC, and LDH was significantly associated with observed covariates, including age, B symptoms, FLIPI risk group, and early event status, indicating that data were not missing completely at random (MCAR) but were consistent with a missing at random (MAR) mechanism."
      ],
      "metadata": {
        "id": "IQRmFfI5zEnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for v in [\"ANC\", \"AMC\", \"ALC\", \"LDH Group\"]:\n",
        "    df[f\"{v}_missing\"] = df[v].isna().astype(int)\n"
      ],
      "metadata": {
        "id": "BXS7eOyb0Q9O"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Evaluable cohort and event rate\n",
        "evaluable = df[df[\"EFS24_bin\"].isin([0, 1])].copy()\n",
        "print(\"EFS24 evaluable n:\", len(evaluable))\n",
        "print(\"EFS24 failure rate:\", evaluable[\"EFS24_bin\"].mean())\n",
        "\n",
        "# 3) Debug: show what values were present\n",
        "print(\"\\nRaw EFS24 value counts:\")\n",
        "print(df[\"EFS24\"].value_counts(dropna=False))\n",
        "\n",
        "print(\"\\nParsed EFS24_bin value counts:\")\n",
        "print(df[\"EFS24_bin\"].value_counts(dropna=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTvQ6SRzbMBw",
        "outputId": "d6570c38-190d-48f3-9b03-c6045fc7ab69"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EFS24 evaluable n: 1743\n",
            "EFS24 failure rate: 0.27309236947791166\n",
            "\n",
            "Raw EFS24 value counts:\n",
            "EFS24\n",
            "Achieved    1267\n",
            "Failed       476\n",
            "NaN          244\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Parsed EFS24_bin value counts:\n",
            "EFS24_bin\n",
            "0.0    1267\n",
            "1.0     476\n",
            "NaN     244\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Baseline benchmark model for EFS24 (logistic regression) ----------\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "# Numeric and categorical predictors (conservative initially)\n",
        "features_num = [\n",
        "    COLS[\"age\"], COLS[\"amc\"], COLS[\"alc\"], COLS[\"anc\"], COLS[\"bili\"],\n",
        "    COLS[\"wbc\"], COLS[\"plt\"], COLS[\"hgb\"], COLS[\"alb\"], COLS[\"cr\"],\n",
        "    COLS[\"flipi\"], COLS[\"ex_sites\"],\n",
        "]\n",
        "features_cat = [\n",
        "    COLS[\"sex\"], COLS[\"race\"], COLS[\"stage\"], COLS[\"stage_group\"],\n",
        "    COLS[\"ps_group\"], COLS[\"ldh_group\"], COLS[\"flipi_group\"],\n",
        "    COLS[\"bm_group\"], COLS[\"fl_grade\"], COLS[\"bulky\"], COLS[\"b_symptoms\"],\n",
        "]\n",
        "\n",
        "# Keep only columns that exist\n",
        "features_num = [c for c in features_num if c in evaluable.columns]\n",
        "features_cat = [c for c in features_cat if c in evaluable.columns]\n",
        "\n",
        "X = evaluable[features_num + features_cat].copy()\n",
        "y = evaluable[\"EFS24_bin\"].astype(int).values\n",
        "\n",
        "print(\"\\nUsing numeric features:\", features_num)\n",
        "print(\"Using categorical features:\", features_cat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q3QZuj0cocG",
        "outputId": "bcd52cee-06b7-4943-d8cf-a9305156e63f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using numeric features: ['Age @ Diagnosis', 'AMC', 'ALC', 'ANC', 'FLIPI', 'Num of Ex. Sites']\n",
            "Using categorical features: ['Gender', 'Race', 'Ann Arbor Stage', 'Ann Arbor Stage Group', 'PS Group', 'LDH Group', 'FLIPI Group', 'BM Involvement Group', 'FL Grade', 'Bulky Disease', 'B Symptoms']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing pipeline (impute + scale numeric; impute + one-hot categorical)\n",
        "pre = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", Pipeline([\n",
        "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "            (\"sc\", StandardScaler())\n",
        "        ]), features_num),\n",
        "        (\"cat\", Pipeline([\n",
        "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "            (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "        ]), features_cat),\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "\n",
        "#  4) Model 1: Regularized logistic regression baseline (elastic net)\n",
        "# -------------------------\n",
        "base_clf = LogisticRegression(\n",
        "    penalty=\"elasticnet\",\n",
        "    solver=\"saga\",\n",
        "    l1_ratio=0.2,      # adjust later in tuning\n",
        "    C=1.0,             # adjust later in tuning\n",
        "    max_iter=8000,\n",
        "    class_weight=None  # consider \"balanced\" only if needed\n",
        ")\n",
        "\n",
        "pipe = Pipeline([\n",
        "    (\"pre\", pre),\n",
        "    (\"clf\", base_clf)\n",
        "])\n",
        "\n",
        "# -------------------------\n",
        "# 5) Cross-validated performance (AUROC, AUPRC, Brier)\n",
        "# -------------------------\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "aucs, aprs, briers = [], [], []\n",
        "oof_pred = np.zeros_like(y, dtype=float)\n",
        "\n",
        "for fold, (tr, te) in enumerate(cv.split(X, y), start=1):\n",
        "    pipe.fit(X.iloc[tr], y[tr])\n",
        "    p = pipe.predict_proba(X.iloc[te])[:, 1]\n",
        "    oof_pred[te] = p\n",
        "\n",
        "    aucs.append(roc_auc_score(y[te], p))\n",
        "    aprs.append(average_precision_score(y[te], p))\n",
        "    briers.append(brier_score_loss(y[te], p))\n",
        "\n",
        "    print(f\"Fold {fold}: AUROC={aucs[-1]:.3f} | AUPRC={aprs[-1]:.3f} | Brier={briers[-1]:.3f}\")\n",
        "\n",
        "print(\"\\nElasticNet LogReg (5-fold CV)\")\n",
        "print(\"AUROC: mean {:.3f} (sd {:.3f})\".format(np.mean(aucs), np.std(aucs)))\n",
        "print(\"AUPRC: mean {:.3f} (sd {:.3f})\".format(np.mean(aprs), np.std(aprs)))\n",
        "print(\"Brier: mean {:.3f} (sd {:.3f})\".format(np.mean(briers), np.std(briers)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR_gt6ak0hNT",
        "outputId": "946c0d52-1cfb-4b91-ceb3-36d25f2d0130"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: AUROC=0.520 | AUPRC=0.298 | Brier=0.208\n",
            "Fold 2: AUROC=0.613 | AUPRC=0.425 | Brier=0.189\n",
            "Fold 3: AUROC=0.596 | AUPRC=0.375 | Brier=0.195\n",
            "Fold 4: AUROC=0.689 | AUPRC=0.499 | Brier=0.180\n",
            "Fold 5: AUROC=0.560 | AUPRC=0.327 | Brier=0.201\n",
            "\n",
            "ElasticNet LogReg (5-fold CV)\n",
            "AUROC: mean 0.595 (sd 0.057)\n",
            "AUPRC: mean 0.385 (sd 0.072)\n",
            "Brier: mean 0.195 (sd 0.010)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Probability calibration (nested CV style, lightweight)\n",
        "#    Use this if you plan to report calibrated risks clinically.\n",
        "# -------------------------\n",
        "# Note: CalibratedClassifierCV performs internal CV; keep it simple initially.\n",
        "calibrated_pipe = Pipeline([\n",
        "    (\"pre\", pre),\n",
        "    (\"cal\", CalibratedClassifierCV(\n",
        "        estimator=base_clf,\n",
        "        method=\"isotonic\",  # or \"sigmoid\" for smaller samples\n",
        "        cv=3\n",
        "    ))\n",
        "])\n",
        "\n",
        "cal_aucs, cal_aprs, cal_briers = [], [], []\n",
        "for fold, (tr, te) in enumerate(cv.split(X, y), start=1):\n",
        "    calibrated_pipe.fit(X.iloc[tr], y[tr])\n",
        "    p = calibrated_pipe.predict_proba(X.iloc[te])[:, 1]\n",
        "    cal_aucs.append(roc_auc_score(y[te], p))\n",
        "    cal_aprs.append(average_precision_score(y[te], p))\n",
        "    cal_briers.append(brier_score_loss(y[te], p))\n",
        "\n",
        "print(\"\\nCalibrated ElasticNet LogReg (isotonic, 5-fold outer CV)\")\n",
        "print(\"AUROC: mean {:.3f} (sd {:.3f})\".format(np.mean(cal_aucs), np.std(cal_aucs)))\n",
        "print(\"AUPRC: mean {:.3f} (sd {:.3f})\".format(np.mean(cal_aprs), np.std(cal_aprs)))\n",
        "print(\"Brier: mean {:.3f} (sd {:.3f})\".format(np.mean(cal_briers), np.std(cal_briers)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddYrI-ty9SfQ",
        "outputId": "695379a7-c76f-434d-a69b-7cee79fa704f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calibrated ElasticNet LogReg (isotonic, 5-fold outer CV)\n",
            "AUROC: mean 0.593 (sd 0.059)\n",
            "AUPRC: mean 0.372 (sd 0.068)\n",
            "Brier: mean 0.194 (sd 0.008)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (Optional) Simple threshold table for clinical-style cut points\n",
        "# -------------------------\n",
        "def threshold_metrics(y_true, p_pred, thr):\n",
        "    y_hat = (p_pred >= thr).astype(int)\n",
        "    tp = np.sum((y_true == 1) & (y_hat == 1))\n",
        "    fp = np.sum((y_true == 0) & (y_hat == 1))\n",
        "    tn = np.sum((y_true == 0) & (y_hat == 0))\n",
        "    fn = np.sum((y_true == 1) & (y_hat == 0))\n",
        "    sens = tp / (tp + fn) if (tp + fn) else np.nan\n",
        "    spec = tn / (tn + fp) if (tn + fp) else np.nan\n",
        "    ppv  = tp / (tp + fp) if (tp + fp) else np.nan\n",
        "    npv  = tn / (tn + fn) if (tn + fn) else np.nan\n",
        "    return {\"thr\": thr, \"sens\": sens, \"spec\": spec, \"ppv\": ppv, \"npv\": npv}\n",
        "\n",
        "print(\"\\nThreshold metrics using out-of-fold predictions (uncalibrated baseline):\")\n",
        "for thr in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
        "    m = threshold_metrics(y, oof_pred, thr)\n",
        "    print(\"thr={thr:.1f} | sens={sens:.2f} spec={spec:.2f} ppv={ppv:.2f} npv={npv:.2f}\".format(**m))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXGnAqTM9llq",
        "outputId": "813ab8f7-500a-4815-d94e-81fa9692bd1f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Threshold metrics using out-of-fold predictions (uncalibrated baseline):\n",
            "thr=0.1 | sens=0.99 spec=0.01 ppv=0.27 npv=0.86\n",
            "thr=0.2 | sens=0.80 spec=0.28 ppv=0.30 npv=0.79\n",
            "thr=0.3 | sens=0.42 spec=0.68 ppv=0.33 npv=0.76\n",
            "thr=0.4 | sens=0.18 spec=0.91 ppv=0.44 npv=0.75\n",
            "thr=0.5 | sens=0.06 spec=0.97 ppv=0.45 npv=0.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An updated model implementing missing values"
      ],
      "metadata": {
        "id": "bjs4j6QZ-Jmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# EFS24 baseline benchmark modeling with MAR-aware missingness handling\n",
        "#   - EFS24 coded: Achieved / Failed / blank\n",
        "#   - Add missingness indicators for ANC/AMC/ALC/LDH Group\n",
        "#   - 5-fold stratified CV with AUROC, AUPRC, Brier\n",
        "# =========================\n",
        "\n",
        "# 2) Create missingness indicators (MAR-aware)\n",
        "# -------------------------\n",
        "missing_targets = [\"anc\", \"amc\", \"alc\", \"ldh_group\"]\n",
        "for key in missing_targets:\n",
        "    col = COLS[key]\n",
        "    if col not in evaluable.columns:\n",
        "        raise KeyError(f\"Missing expected column for missingness indicator: '{col}'\")\n",
        "    evaluable[f\"{col}__missing\"] = evaluable[col].isna().astype(int)\n",
        "\n",
        "# Optionally coerce numeric labs/age to numeric\n",
        "numeric_to_coerce = [COLS[\"age\"], COLS[\"anc\"], COLS[\"amc\"], COLS[\"alc\"],\n",
        "                     COLS.get(\"wbc\"), COLS.get(\"plt\"), COLS.get(\"hgb\"),\n",
        "                     COLS.get(\"alb\"), COLS.get(\"cr\"), COLS.get(\"bili\"),\n",
        "                     COLS.get(\"ex_sites\"), COLS.get(\"flipi\")]\n",
        "numeric_to_coerce = [c for c in numeric_to_coerce if c is not None and c in evaluable.columns]\n",
        "for c in numeric_to_coerce:\n",
        "    evaluable[c] = pd.to_numeric(evaluable[c], errors=\"coerce\")\n",
        "\n",
        "#  Define feature sets\n",
        "#    - We'll run two models:\n",
        "#        A) clinical-only WITHOUT ANC/AMC/ALC/LDH_group\n",
        "#        B) clinical+labs WITH ANC/AMC/ALC/LDH_group + missing indicators\n",
        "# -------------------------\n",
        "\n",
        "# Base clinical predictors (no labs)\n",
        "features_num_base = [\n",
        "    COLS[\"age\"],\n",
        "    COLS[\"flipi\"],      # keep if available and numeric\n",
        "    COLS[\"ex_sites\"],   # keep if available and numeric\n",
        "]\n",
        "features_cat_base = [\n",
        "    COLS[\"sex\"], COLS[\"race\"], COLS[\"stage\"], COLS[\"stage_group\"],\n",
        "    COLS[\"ps_group\"], COLS[\"flipi_group\"], COLS[\"fl_grade\"],\n",
        "    COLS[\"bm_group\"], COLS[\"bulky\"], COLS[\"b_symptoms\"],\n",
        "]\n",
        "\n",
        "# Labs to include in the expanded model\n",
        "features_num_labs = [COLS[\"anc\"], COLS[\"amc\"], COLS[\"alc\"]]\n",
        "features_cat_labs = [COLS[\"ldh_group\"]]\n",
        "\n",
        "# Add missingness indicators (these are numeric 0/1)\n",
        "missing_indicator_cols = [f\"{COLS[k]}__missing\" for k in missing_targets]\n",
        "\n",
        "# Keep only existing columns\n",
        "def keep_existing(cols, df_):\n",
        "    return [c for c in cols if c in df_.columns]\n",
        "\n",
        "features_num_base = keep_existing(features_num_base, evaluable)\n",
        "features_cat_base = keep_existing(features_cat_base, evaluable)\n",
        "\n",
        "features_num_labs = keep_existing(features_num_labs, evaluable)\n",
        "features_cat_labs = keep_existing(features_cat_labs, evaluable)\n",
        "missing_indicator_cols = keep_existing(missing_indicator_cols, evaluable)\n",
        "\n",
        "# Define two feature configurations\n",
        "FEATURE_SETS = {\n",
        "    \"ClinicalOnly\": {\n",
        "        \"num\": features_num_base,\n",
        "        \"cat\": features_cat_base,\n",
        "        \"extra_num\": []  # no missing indicators here\n",
        "    },\n",
        "    \"ClinicalPlusLabs_MissInd\": {\n",
        "        \"num\": features_num_base + features_num_labs + missing_indicator_cols,\n",
        "        \"cat\": features_cat_base + features_cat_labs,\n",
        "        \"extra_num\": []  # already included in num\n",
        "    }\n",
        "}\n",
        "\n",
        "y = evaluable[\"EFS24_bin\"].astype(int).values\n",
        "\n",
        "\n",
        "# Helper: build pipeline and evaluate with CV\n",
        "# -------------------------\n",
        "def build_pipeline(num_cols, cat_cols):\n",
        "    pre = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", Pipeline([\n",
        "                (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "                (\"sc\", StandardScaler())\n",
        "            ]), num_cols),\n",
        "            (\"cat\", Pipeline([\n",
        "                (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "            ]), cat_cols),\n",
        "        ],\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "\n",
        "    clf = LogisticRegression(\n",
        "        penalty=\"elasticnet\",\n",
        "        solver=\"saga\",\n",
        "        l1_ratio=0.2,\n",
        "        C=1.0,\n",
        "        max_iter=8000\n",
        "    )\n",
        "\n",
        "    return Pipeline([(\"pre\", pre), (\"clf\", clf)])\n",
        "\n",
        "def cv_eval(X, y, pipeline, n_splits=5, seed=42):\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    aucs, aprs, briers = [], [], []\n",
        "    oof = np.zeros_like(y, dtype=float)\n",
        "\n",
        "    for fold, (tr, te) in enumerate(cv.split(X, y), start=1):\n",
        "        pipeline.fit(X.iloc[tr], y[tr])\n",
        "        p = pipeline.predict_proba(X.iloc[te])[:, 1]\n",
        "        oof[te] = p\n",
        "        aucs.append(roc_auc_score(y[te], p))\n",
        "        aprs.append(average_precision_score(y[te], p))\n",
        "        briers.append(brier_score_loss(y[te], p))\n",
        "        print(f\"  Fold {fold}: AUROC={aucs[-1]:.3f} | AUPRC={aprs[-1]:.3f} | Brier={briers[-1]:.3f}\")\n",
        "\n",
        "    return {\n",
        "        \"auroc_mean\": float(np.mean(aucs)),\n",
        "        \"auroc_sd\": float(np.std(aucs)),\n",
        "        \"auprc_mean\": float(np.mean(aprs)),\n",
        "        \"auprc_sd\": float(np.std(aprs)),\n",
        "        \"brier_mean\": float(np.mean(briers)),\n",
        "        \"brier_sd\": float(np.std(briers)),\n",
        "        \"oof_pred\": oof\n",
        "    }\n",
        "\n",
        "\n",
        "# Run both baseline models\n",
        "# -------------------------\n",
        "results = {}\n",
        "\n",
        "for name, cfg in FEATURE_SETS.items():\n",
        "    num_cols = cfg[\"num\"]\n",
        "    cat_cols = cfg[\"cat\"]\n",
        "\n",
        "    print(f\"\\n=== Model: {name} ===\")\n",
        "    print(\"Numeric cols:\", num_cols)\n",
        "    print(\"Categorical cols:\", cat_cols)\n",
        "\n",
        "    X = evaluable[num_cols + cat_cols].copy()\n",
        "\n",
        "    pipe = build_pipeline(num_cols, cat_cols)\n",
        "    res = cv_eval(X, y, pipe, n_splits=5, seed=42)\n",
        "\n",
        "    print(f\"\\n{name} summary:\")\n",
        "    print(\"  AUROC: mean {:.3f} (sd {:.3f})\".format(res[\"auroc_mean\"], res[\"auroc_sd\"]))\n",
        "    print(\"  AUPRC: mean {:.3f} (sd {:.3f})\".format(res[\"auprc_mean\"], res[\"auprc_sd\"]))\n",
        "    print(\"  Brier: mean {:.3f} (sd {:.3f})\".format(res[\"brier_mean\"], res[\"brier_sd\"]))\n",
        "\n",
        "    results[name] = res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuvJtP2s-O_G",
        "outputId": "44ff9427-f1bc-4b7a-ad7b-29a407e05a5f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Model: ClinicalOnly ===\n",
            "Numeric cols: ['Age @ Diagnosis', 'FLIPI', 'Num of Ex. Sites']\n",
            "Categorical cols: ['Gender', 'Race', 'Ann Arbor Stage', 'Ann Arbor Stage Group', 'PS Group', 'FLIPI Group', 'FL Grade', 'BM Involvement Group', 'Bulky Disease', 'B Symptoms']\n",
            "  Fold 1: AUROC=0.523 | AUPRC=0.300 | Brier=0.206\n",
            "  Fold 2: AUROC=0.604 | AUPRC=0.424 | Brier=0.190\n",
            "  Fold 3: AUROC=0.587 | AUPRC=0.362 | Brier=0.196\n",
            "  Fold 4: AUROC=0.693 | AUPRC=0.491 | Brier=0.182\n",
            "  Fold 5: AUROC=0.557 | AUPRC=0.330 | Brier=0.201\n",
            "\n",
            "ClinicalOnly summary:\n",
            "  AUROC: mean 0.593 (sd 0.057)\n",
            "  AUPRC: mean 0.381 (sd 0.069)\n",
            "  Brier: mean 0.195 (sd 0.008)\n",
            "\n",
            "=== Model: ClinicalPlusLabs_MissInd ===\n",
            "Numeric cols: ['Age @ Diagnosis', 'FLIPI', 'Num of Ex. Sites', 'ANC', 'AMC', 'ALC', 'ANC__missing', 'AMC__missing', 'ALC__missing', 'LDH Group__missing']\n",
            "Categorical cols: ['Gender', 'Race', 'Ann Arbor Stage', 'Ann Arbor Stage Group', 'PS Group', 'FLIPI Group', 'FL Grade', 'BM Involvement Group', 'Bulky Disease', 'B Symptoms', 'LDH Group']\n",
            "  Fold 1: AUROC=0.533 | AUPRC=0.302 | Brier=0.207\n",
            "  Fold 2: AUROC=0.628 | AUPRC=0.429 | Brier=0.188\n",
            "  Fold 3: AUROC=0.617 | AUPRC=0.382 | Brier=0.194\n",
            "  Fold 4: AUROC=0.690 | AUPRC=0.524 | Brier=0.179\n",
            "  Fold 5: AUROC=0.562 | AUPRC=0.330 | Brier=0.203\n",
            "\n",
            "ClinicalPlusLabs_MissInd summary:\n",
            "  AUROC: mean 0.606 (sd 0.055)\n",
            "  AUPRC: mean 0.393 (sd 0.078)\n",
            "  Brier: mean 0.194 (sd 0.010)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick comparison\n",
        "# -------------------------\n",
        "print(\"\\n=== Comparison ===\")\n",
        "for metric in [\"auroc_mean\", \"auprc_mean\", \"brier_mean\"]:\n",
        "    print(metric,\n",
        "          \"ClinicalOnly:\", results[\"ClinicalOnly\"][metric],\n",
        "          \"| ClinicalPlusLabs_MissInd:\", results[\"ClinicalPlusLabs_MissInd\"][metric])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BODzquLT_qhK",
        "outputId": "33f31379-087f-4838-fbf7-6789324c5333"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Comparison ===\n",
            "auroc_mean ClinicalOnly: 0.5926474814998031 | ClinicalPlusLabs_MissInd: 0.6058922942646523\n",
            "auprc_mean ClinicalOnly: 0.3813901953922725 | ClinicalPlusLabs_MissInd: 0.3933866815014491\n",
            "brier_mean ClinicalOnly: 0.19497140601809054 | ClinicalPlusLabs_MissInd: 0.19414684202479476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# “Baseline clinical features demonstrated modest discrimination for early event-free survival failure. Inclusion of laboratory variables with explicit modeling of missingness yielded incremental improvements in discrimination and precision without compromising calibration.”"
      ],
      "metadata": {
        "id": "MkbeURZ2ANT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Boosted tree baseline\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "def keep_existing(cols):\n",
        "    return [c for c in cols if c in evaluable.columns]\n",
        "\n",
        "features_num_base = keep_existing(features_num_base)\n",
        "features_cat_base = keep_existing(features_cat_base)\n",
        "features_num_labs = keep_existing(features_num_labs)\n",
        "features_cat_labs = keep_existing(features_cat_labs)\n",
        "missing_indicator_cols = keep_existing(missing_indicator_cols)\n",
        "\n",
        "FEATURE_SETS = {\n",
        "    \"ClinicalOnly\": {\n",
        "        \"num\": features_num_base,\n",
        "        \"cat\": features_cat_base\n",
        "    },\n",
        "    \"ClinicalPlusLabs_MissInd\": {\n",
        "        \"num\": features_num_base + features_num_labs + missing_indicator_cols,\n",
        "        \"cat\": features_cat_base + features_cat_labs\n",
        "    }\n",
        "}\n",
        "\n",
        "# Preprocessing + model\n",
        "#    - Numeric: no imputation needed for HGB (it can handle NaNs),\n",
        "#      but we DO want imputation for missing indicator cols? they are 0/1 already.\n",
        "#      We'll pass numeric through as-is.\n",
        "#    - Categorical: impute most frequent, one-hot encode.\n",
        "# -------------------------\n",
        "def make_pipeline(num_cols, cat_cols, calibrated=False):\n",
        "    pre = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", \"passthrough\", num_cols),\n",
        "            (\"cat\", Pipeline([\n",
        "                (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "            ]), cat_cols),\n",
        "        ],\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "\n",
        "    hgb = HistGradientBoostingClassifier(\n",
        "        loss=\"log_loss\",\n",
        "        learning_rate=0.05,\n",
        "        max_depth=3,\n",
        "        max_iter=500,\n",
        "        min_samples_leaf=30,\n",
        "        l2_regularization=0.0,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    if not calibrated:\n",
        "        return Pipeline([(\"pre\", pre), (\"clf\", hgb)])\n",
        "\n",
        "    # Calibrate predicted probabilities (recommended for continuous risk reporting)\n",
        "    # Using sigmoid for stability; isotonic can overfit in smaller folds.\n",
        "    cal = CalibratedClassifierCV(estimator=hgb, method=\"sigmoid\", cv=3)\n",
        "    return Pipeline([(\"pre\", pre), (\"cal\", cal)])\n",
        "\n",
        "# Cross-validated evaluation (with out-of-fold predictions)\n",
        "# -------------------------\n",
        "def cv_eval(X, y, pipeline, n_splits=5, seed=42):\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    aucs, aprs, briers = [], [], []\n",
        "    oof = np.zeros_like(y, dtype=float)\n",
        "\n",
        "    for fold, (tr, te) in enumerate(cv.split(X, y), start=1):\n",
        "        pipeline.fit(X.iloc[tr], y[tr])\n",
        "        # calibrated pipeline returns predict_proba; uncalibrated also does\n",
        "        p = pipeline.predict_proba(X.iloc[te])[:, 1]\n",
        "        oof[te] = p\n",
        "        aucs.append(roc_auc_score(y[te], p))\n",
        "        aprs.append(average_precision_score(y[te], p))\n",
        "        briers.append(brier_score_loss(y[te], p))\n",
        "        print(f\"  Fold {fold}: AUROC={aucs[-1]:.3f} | AUPRC={aprs[-1]:.3f} | Brier={briers[-1]:.3f}\")\n",
        "\n",
        "    return {\n",
        "        \"auroc_mean\": float(np.mean(aucs)),\n",
        "        \"auroc_sd\": float(np.std(aucs)),\n",
        "        \"auprc_mean\": float(np.mean(aprs)),\n",
        "        \"auprc_sd\": float(np.std(aprs)),\n",
        "        \"brier_mean\": float(np.mean(briers)),\n",
        "        \"brier_sd\": float(np.std(briers)),\n",
        "        \"oof_pred\": oof\n",
        "    }\n",
        "\n",
        "# 4) Run: uncalibrated and calibrated boosted tree, for both feature sets\n",
        "# -------------------------\n",
        "results = {}\n",
        "\n",
        "for set_name, cfg in FEATURE_SETS.items():\n",
        "    num_cols, cat_cols = cfg[\"num\"], cfg[\"cat\"]\n",
        "    X = evaluable[num_cols + cat_cols].copy()\n",
        "\n",
        "    print(f\"\\n=== Boosted Tree (HGB) | {set_name} | Uncalibrated ===\")\n",
        "    pipe = make_pipeline(num_cols, cat_cols, calibrated=False)\n",
        "    res_uncal = cv_eval(X, y, pipe, n_splits=5, seed=42)\n",
        "    print(f\"{set_name} HGB Uncal summary: AUROC {res_uncal['auroc_mean']:.3f} (sd {res_uncal['auroc_sd']:.3f}) | \"\n",
        "          f\"AUPRC {res_uncal['auprc_mean']:.3f} | Brier {res_uncal['brier_mean']:.3f}\")\n",
        "\n",
        "    print(f\"\\n=== Boosted Tree (HGB) | {set_name} | Calibrated (sigmoid) ===\")\n",
        "    pipe_cal = make_pipeline(num_cols, cat_cols, calibrated=True)\n",
        "    res_cal = cv_eval(X, y, pipe_cal, n_splits=5, seed=42)\n",
        "    print(f\"{set_name} HGB Cal summary:   AUROC {res_cal['auroc_mean']:.3f} (sd {res_cal['auroc_sd']:.3f}) | \"\n",
        "          f\"AUPRC {res_cal['auprc_mean']:.3f} | Brier {res_cal['brier_mean']:.3f}\")\n",
        "\n",
        "    results[(set_name, \"uncal\")] = res_uncal\n",
        "    results[(set_name, \"cal\")] = res_cal\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEOExdeYA6Fr",
        "outputId": "eaba5a96-f085-4b50-902b-4cac14550063"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Boosted Tree (HGB) | ClinicalOnly | Uncalibrated ===\n",
            "  Fold 1: AUROC=0.538 | AUPRC=0.310 | Brier=0.215\n",
            "  Fold 2: AUROC=0.596 | AUPRC=0.369 | Brier=0.196\n",
            "  Fold 3: AUROC=0.526 | AUPRC=0.318 | Brier=0.214\n",
            "  Fold 4: AUROC=0.659 | AUPRC=0.491 | Brier=0.181\n",
            "  Fold 5: AUROC=0.564 | AUPRC=0.348 | Brier=0.204\n",
            "ClinicalOnly HGB Uncal summary: AUROC 0.577 (sd 0.048) | AUPRC 0.367 | Brier 0.202\n",
            "\n",
            "=== Boosted Tree (HGB) | ClinicalOnly | Calibrated (sigmoid) ===\n",
            "  Fold 1: AUROC=0.542 | AUPRC=0.320 | Brier=0.198\n",
            "  Fold 2: AUROC=0.618 | AUPRC=0.396 | Brier=0.193\n",
            "  Fold 3: AUROC=0.525 | AUPRC=0.326 | Brier=0.199\n",
            "  Fold 4: AUROC=0.661 | AUPRC=0.445 | Brier=0.195\n",
            "  Fold 5: AUROC=0.580 | AUPRC=0.388 | Brier=0.194\n",
            "ClinicalOnly HGB Cal summary:   AUROC 0.585 (sd 0.049) | AUPRC 0.375 | Brier 0.196\n",
            "\n",
            "=== Boosted Tree (HGB) | ClinicalPlusLabs_MissInd | Uncalibrated ===\n",
            "  Fold 1: AUROC=0.562 | AUPRC=0.347 | Brier=0.211\n",
            "  Fold 2: AUROC=0.608 | AUPRC=0.391 | Brier=0.197\n",
            "  Fold 3: AUROC=0.546 | AUPRC=0.334 | Brier=0.217\n",
            "  Fold 4: AUROC=0.605 | AUPRC=0.361 | Brier=0.202\n",
            "  Fold 5: AUROC=0.561 | AUPRC=0.352 | Brier=0.212\n",
            "ClinicalPlusLabs_MissInd HGB Uncal summary: AUROC 0.576 (sd 0.025) | AUPRC 0.357 | Brier 0.208\n",
            "\n",
            "=== Boosted Tree (HGB) | ClinicalPlusLabs_MissInd | Calibrated (sigmoid) ===\n",
            "  Fold 1: AUROC=0.575 | AUPRC=0.347 | Brier=0.196\n",
            "  Fold 2: AUROC=0.600 | AUPRC=0.386 | Brier=0.193\n",
            "  Fold 3: AUROC=0.565 | AUPRC=0.356 | Brier=0.197\n",
            "  Fold 4: AUROC=0.599 | AUPRC=0.380 | Brier=0.195\n",
            "  Fold 5: AUROC=0.587 | AUPRC=0.370 | Brier=0.194\n",
            "ClinicalPlusLabs_MissInd HGB Cal summary:   AUROC 0.585 (sd 0.014) | AUPRC 0.368 | Brier 0.195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Create risk groups from calibrated out-of-fold predictions (recommended)\n",
        "#    Example: tertiles (low/intermediate/high) or top-quintile high risk.\n",
        "# -------------------------\n",
        "# Choose which model's predictions you want to use for risk grouping:\n",
        "chosen = (\"ClinicalPlusLabs_MissInd\", \"cal\")\n",
        "p = results[chosen][\"oof_pred\"]\n",
        "\n",
        "tmp = evaluable.copy()\n",
        "tmp[\"risk_prob\"] = p\n",
        "\n",
        "# Tertiles\n",
        "tmp[\"risk_tertile\"] = pd.qcut(tmp[\"risk_prob\"], q=3, labels=[\"Low\", \"Intermediate\", \"High\"])\n",
        "\n",
        "# Top 20% high-risk flag (common operationalization)\n",
        "thr_80 = np.quantile(tmp[\"risk_prob\"], 0.80)\n",
        "tmp[\"high_risk_top20\"] = (tmp[\"risk_prob\"] >= thr_80).astype(int)\n",
        "\n",
        "print(\"\\nRisk grouping summary (chosen model:\", chosen, \")\")\n",
        "print(tmp.groupby(\"risk_tertile\")[\"EFS24_bin\"].mean())\n",
        "print(\"Top 20% threshold:\", thr_80)\n",
        "print(\"Failure rate in top20%:\", tmp.loc[tmp[\"high_risk_top20\"]==1, \"EFS24_bin\"].mean())\n",
        "print(\"Failure rate in bottom80%:\", tmp.loc[tmp[\"high_risk_top20\"]==0, \"EFS24_bin\"].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrNLhlwlB-Lr",
        "outputId": "4c4efa63-1f90-4a8e-951b-fd97ce40d202"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Risk grouping summary (chosen model: ('ClinicalPlusLabs_MissInd', 'cal') )\n",
            "risk_tertile\n",
            "Low             0.225473\n",
            "Intermediate    0.259897\n",
            "High            0.333907\n",
            "Name: EFS24_bin, dtype: float64\n",
            "Top 20% threshold: 0.31097869149520746\n",
            "Failure rate in top20%: 0.36962750716332377\n",
            "Failure rate in bottom80%: 0.24892395982783358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1010437205.py:19: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  print(tmp.groupby(\"risk_tertile\")[\"EFS24_bin\"].mean())\n"
          ]
        }
      ]
    }
  ]
}